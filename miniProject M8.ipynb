{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e72cc4-ff48-4cdf-a535-450b983d8720",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Function to calculate helpfulness score (hij)\n",
    "def calculate_helpfulness_score(user_reviews):\n",
    "    # Group reviews by user and item\n",
    "    result = {}\n",
    "    \n",
    "    for review in user_reviews:\n",
    "        user_id = review.get('reviewerID')\n",
    "        item_id = review.get('asin')\n",
    "        helpful = review.get('helpful', [0, 0])\n",
    "        \n",
    "        # Extract helpful votes and total votes\n",
    "        helpful_votes = helpful[0]\n",
    "        total_votes = helpful[1]\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if total_votes == 0:\n",
    "            total_votes = 1\n",
    "            \n",
    "        # Calculate bij = (# helpful votes)² / # total votes\n",
    "        bij = (helpful_votes ** 2) / total_votes\n",
    "        \n",
    "        # Store bij values to later calculate hij\n",
    "        if item_id not in result:\n",
    "            result[item_id] = {}\n",
    "        \n",
    "        result[item_id][user_id] = {'bij': bij, 'review': review}\n",
    "    \n",
    "    # Calculate hij = bij / ∑bxj for each user-item pair\n",
    "    for item_id, users in result.items():\n",
    "        sum_bxj = sum(user_data['bij'] for user_data in users.values())\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if sum_bxj == 0:\n",
    "            sum_bxj = 1\n",
    "            \n",
    "        for user_id in users:\n",
    "            users[user_id]['hij'] = users[user_id]['bij'] / sum_bxj\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Function to calculate reliability scores (rhij)\n",
    "def calculate_reliability_scores(helpfulness_data, alpha=0.5):\n",
    "    for item_id, users in helpfulness_data.items():\n",
    "        # Convert users to a list for indexing\n",
    "        user_list = list(users.keys())\n",
    "        n_prime = len(user_list)\n",
    "        \n",
    "        # Calculate zij and qij for each user\n",
    "        for i, user_id in enumerate(user_list):\n",
    "            # Calculate zij for most recent review reliability\n",
    "            zij = sum(1/(e**2) for e in range(1, n_prime-i+1))\n",
    "            \n",
    "            # For simplicity, using a constant for σ²ᵢⱼ\n",
    "            sigma_squared = 1.0\n",
    "            \n",
    "            # Calculate qij for top ranking reviewer reliability\n",
    "            qij = (1/sigma_squared) * (n_prime - i)\n",
    "            \n",
    "            users[user_id]['zij'] = zij\n",
    "            users[user_id]['qij'] = qij\n",
    "        \n",
    "        # Calculate mostij and topij\n",
    "        sum_zxj = sum(users[user_id]['zij'] for user_id in user_list)\n",
    "        sum_qxj = sum(users[user_id]['qij'] for user_id in user_list)\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if sum_zxj == 0:\n",
    "            sum_zxj = 1\n",
    "        if sum_qxj == 0:\n",
    "            sum_qxj = 1\n",
    "            \n",
    "        for user_id in user_list:\n",
    "            users[user_id]['mostij'] = users[user_id]['zij'] / sum_zxj\n",
    "            users[user_id]['topij'] = users[user_id]['qij'] / sum_qxj\n",
    "            \n",
    "            # Calculate combined reliability score (dij)\n",
    "            dij = alpha * users[user_id]['topij'] + (1-alpha) * users[user_id]['mostij']\n",
    "            \n",
    "            # For this implementation, we'll use dij as rhij\n",
    "            users[user_id]['rhij'] = dij\n",
    "            \n",
    "            # Calculate average of hij and rhij\n",
    "            users[user_id]['avg_score'] = (users[user_id]['hij'] + users[user_id]['rhij']) / 2\n",
    "    \n",
    "    return helpfulness_data\n",
    "\n",
    "# Function to generate the CSV file\n",
    "def generate_csv(processed_data, output_path):\n",
    "    # Prepare data for CSV\n",
    "    csv_data = []\n",
    "    \n",
    "    for item_id, users in processed_data.items():\n",
    "        for user_id, scores in users.items():\n",
    "            csv_data.append({\n",
    "                'user_id': user_id,\n",
    "                'item_id': item_id,\n",
    "                'avg_of_rhij_and_hij': scores['avg_score']\n",
    "            })\n",
    "    \n",
    "    # Create DataFrame and save as CSV\n",
    "    df = pd.DataFrame(csv_data)\n",
    "    df.to_csv(output_path, index=False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Main function to process the data\n",
    "def process_review_data(file_path, output_path):\n",
    "    # Load the JSON data from the gzip file\n",
    "    data = []\n",
    "    \n",
    "    try:\n",
    "        with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                data.append(json.loads(line))\n",
    "        \n",
    "        # Calculate helpfulness scores\n",
    "        helpfulness_data = calculate_helpfulness_score(data)\n",
    "        \n",
    "        # Calculate reliability scores and average\n",
    "        processed_data = calculate_reliability_scores(helpfulness_data)\n",
    "        \n",
    "        # Generate and save CSV\n",
    "        df = generate_csv(processed_data, output_path)\n",
    "        \n",
    "        print(f\"CSV file successfully generated at {output_path}\")\n",
    "        print(f\"Sample of the generated data:\")\n",
    "        print(df.head())\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {file_path} was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing the data: {str(e)}\")\n",
    "\n",
    "# File paths\n",
    "file_path = \"C:\\\\Users\\\\KIIT\\\\Downloads\\\\Appliances.json.gz\"\n",
    "output_path = \"C:\\\\Users\\\\KIIT\\\\Downloads\\\\average_scores1.csv\"\n",
    "\n",
    "# Process the data\n",
    "process_review_data(file_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "828e8142-18b4-4fb4-b422-c38d2ce90583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Using file at: C:\\Users\\KIIT\\RecommendationData\\Arts.txt\n",
      "\n",
      " CSV saved to: C:\\Users\\KIIT\\RecommendationData\\average_scores12.csv\n",
      "\n",
      " Sample of dataframe:\n",
      "          user_id     item_id  avg_of_rhij_and_hij\n",
      "0  A1QA985ULVCQOB  B000GKXY4S             0.833333\n",
      "1   ALCX2ELNHLQA7  B000GKXY4S             0.166667\n",
      "2  A2M2M4R1KG5WOL  B000140KIW             0.666667\n",
      "3   ARQAQ6ZYMFPCA  B000140KIW             0.133333\n",
      "4  A3FPG4LAJ1HOHZ  B000140KIW             0.100000\n",
      "\n",
      " Original Rating Matrix (First 5x5):\n",
      "item_id                048629241X  0618307222  0698109228  0806998075  \\\n",
      "user_id                                                                 \n",
      "A002211213O7OZD4NB6T4         0.0         0.0         0.0         0.0   \n",
      "A00890531BOEEDK31WCBE         0.0         0.0         0.0         0.0   \n",
      "A01676021JTRZ0XE5YS4A         0.0         0.0         0.0         0.0   \n",
      "A03007643BIO3UI6ZO6ZR         0.0         0.0         0.0         0.0   \n",
      "A03043323VAO4JWT2G7HF         0.0         0.0         0.0         0.0   \n",
      "\n",
      "item_id                0848724747  \n",
      "user_id                            \n",
      "A002211213O7OZD4NB6T4         0.0  \n",
      "A00890531BOEEDK31WCBE         0.0  \n",
      "A01676021JTRZ0XE5YS4A         0.0  \n",
      "A03007643BIO3UI6ZO6ZR         0.0  \n",
      "A03043323VAO4JWT2G7HF         0.0  \n",
      "\n",
      " Predicted Rating Matrix (First 5x5):\n",
      "item_id                  048629241X    0618307222    0698109228    0806998075  \\\n",
      "user_id                                                                         \n",
      "A002211213O7OZD4NB6T4 -2.855506e-37  2.189492e-22  2.215791e-27  5.002722e-23   \n",
      "A00890531BOEEDK31WCBE -2.553438e-29  1.157539e-13  6.501135e-19  2.645213e-14   \n",
      "A01676021JTRZ0XE5YS4A  3.114996e-37  1.919728e-21  1.117205e-26  4.386475e-22   \n",
      "A03007643BIO3UI6ZO6ZR  5.167168e-22  2.263804e-14  1.300919e-13  5.404263e-15   \n",
      "A03043323VAO4JWT2G7HF  2.927752e-30  1.605075e-13 -4.093090e-23  3.667710e-14   \n",
      "\n",
      "item_id                  0848724747  \n",
      "user_id                              \n",
      "A002211213O7OZD4NB6T4  2.342959e-23  \n",
      "A00890531BOEEDK31WCBE  1.240220e-14  \n",
      "A01676021JTRZ0XE5YS4A  2.054940e-22  \n",
      "A03007643BIO3UI6ZO6ZR  2.427910e-15  \n",
      "A03043323VAO4JWT2G7HF  1.719574e-14  \n",
      "\n",
      " Regularized Loss: 1527.0181\n",
      "\n",
      " Top 10 recommendations for user A002211213O7OZD4NB6T4:\n",
      "item_id\n",
      "B0007LHK2I    1.203064e-20\n",
      "B0009PRWM0    7.846474e-21\n",
      "B0002TTKOQ    7.523094e-21\n",
      "B0002TTL4K    7.523094e-21\n",
      "B000K9DJYA    7.485646e-21\n",
      "B000K9FH5E    7.485646e-21\n",
      "B000K9GL3G    7.485646e-21\n",
      "B000K9FH5O    7.485646e-21\n",
      "B000K9BP0U    7.485646e-21\n",
      "B0002TTI70    4.765655e-21\n",
      "dtype: float64\n",
      "\n",
      " MSE on test set: 0.0620\n",
      " Hit Ratio@10: 0.0044\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tempfile\n",
    "import subprocess\n",
    "\n",
    "# ---------- STEP 1: Parse Arts.txt ----------\n",
    "def parse_arts_file(file_path):\n",
    "    reviews = []\n",
    "    current_review = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            if line.startswith('product/productId:'):\n",
    "                if current_review:\n",
    "                    reviews.append(current_review)\n",
    "                    current_review = {}\n",
    "                current_review['product/productId'] = line.split(': ')[1]\n",
    "            elif line.startswith('review/userId:'):\n",
    "                current_review['review/userId'] = line.split(': ')[1]\n",
    "            elif line.startswith('review/helpfulness:'):\n",
    "                helpful = line.split(': ')[1].split('/')\n",
    "                try:\n",
    "                    current_review['review/helpfulness'] = [int(helpful[0]), int(helpful[1])]\n",
    "                except:\n",
    "                    current_review['review/helpfulness'] = [0, 1]\n",
    "    if current_review:\n",
    "        reviews.append(current_review)\n",
    "    return reviews\n",
    "\n",
    "# ---------- STEP 2: Helpfulness and Reliability ----------\n",
    "def calculate_helpfulness_score(reviews):\n",
    "    result = {}\n",
    "    for review in reviews:\n",
    "        user_id = review.get('review/userId')\n",
    "        item_id = review.get('product/productId')\n",
    "        helpful = review.get('review/helpfulness', [0, 0])\n",
    "        helpful_votes = helpful[0]\n",
    "        total_votes = helpful[1] if helpful[1] != 0 else 1\n",
    "        bij = (helpful_votes ** 2) / total_votes\n",
    "        if item_id not in result:\n",
    "            result[item_id] = {}\n",
    "        result[item_id][user_id] = {'bij': bij, 'review': review}\n",
    "    for item_id, users in result.items():\n",
    "        sum_bxj = sum(user['bij'] for user in users.values()) or 1\n",
    "        for user_id in users:\n",
    "            users[user_id]['hij'] = users[user_id]['bij'] / sum_bxj\n",
    "    return result\n",
    "\n",
    "def calculate_reliability_scores(helpfulness_data, alpha=0.5):\n",
    "    for item_id, users in helpfulness_data.items():\n",
    "        user_list = list(users.keys())\n",
    "        n_prime = len(user_list)\n",
    "        for i, user_id in enumerate(user_list):\n",
    "            zij = sum(1 / (np.e**2) for _ in range(1, max(n_prime - i + 1, 2)))\n",
    "            sigma_squared = 1.0\n",
    "            qij = (1 / sigma_squared) * (n_prime - i)\n",
    "            users[user_id]['zij'] = zij\n",
    "            users[user_id]['qij'] = qij\n",
    "        sum_zxj = sum(users[u]['zij'] for u in user_list)\n",
    "        sum_qxj = sum(users[u]['qij'] for u in user_list)\n",
    "        for user_id in user_list:\n",
    "            users[user_id]['mostij'] = users[user_id]['zij'] / sum_zxj\n",
    "            users[user_id]['topij'] = users[user_id]['qij'] / sum_qxj\n",
    "            users[user_id]['rhij'] = alpha * users[user_id]['topij'] + (1 - alpha) * users[user_id]['mostij']\n",
    "            users[user_id]['avg_score'] = (users[user_id]['hij'] + users[user_id]['rhij']) / 2\n",
    "    return helpfulness_data\n",
    "\n",
    "# ---------- STEP 3: Generate DataFrame ----------\n",
    "def generate_dataframe(processed_data):\n",
    "    rows = []\n",
    "    for item_id, users in processed_data.items():\n",
    "        for user_id, data in users.items():\n",
    "            rows.append({\n",
    "                'user_id': user_id,\n",
    "                'item_id': item_id,\n",
    "                'avg_of_rhij_and_hij': data['avg_score']\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ---------- STEP 4: Matrix Factorization ----------\n",
    "def apply_svd(df, k=50):\n",
    "    pivot_df = df.pivot(index='user_id', columns='item_id', values='avg_of_rhij_and_hij').fillna(0)\n",
    "    R = pivot_df.values\n",
    "    U, sigma, Vt = svds(R, k=min(k, min(R.shape)-1))\n",
    "    sigma = np.diag(sigma)\n",
    "    predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n",
    "    return pivot_df, predicted_ratings, U, Vt\n",
    "\n",
    "# ---------- STEP 5: Evaluation ----------\n",
    "def compute_loss(R_true, R_pred, U, Vt, lambda_reg=0.1):\n",
    "    mask = R_true > 0\n",
    "    mse_loss = np.sum((R_true[mask] - R_pred[mask]) ** 2)\n",
    "    reg_term = lambda_reg * (np.sum(U**2) + np.sum(Vt**2))\n",
    "    return mse_loss + reg_term\n",
    "\n",
    "def hit_ratio_at_k(test_R, predicted_R, k=10):\n",
    "    hits = 0\n",
    "    total_users = 0\n",
    "    for user_idx in range(test_R.shape[0]):\n",
    "        true_items = np.where(test_R[user_idx] > 0)[0]\n",
    "        if len(true_items) == 0:\n",
    "            continue\n",
    "        top_k_items = np.argsort(predicted_R[user_idx])[::-1][:k]\n",
    "        if np.intersect1d(true_items, top_k_items).size > 0:\n",
    "            hits += 1\n",
    "        total_users += 1\n",
    "    return hits / total_users if total_users else 0\n",
    "\n",
    "# ---------- STEP 6: Main ----------\n",
    "def main():\n",
    "    # Create safe directory in user's home folder\n",
    "    safe_dir = os.path.join(os.path.expanduser(\"~\"), \"RecommendationData\")\n",
    "    os.makedirs(safe_dir, exist_ok=True)\n",
    "    input_path = os.path.join(safe_dir, \"Arts.txt\")\n",
    "\n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\" Please copy Arts.txt to: {safe_dir}\")\n",
    "        print(\"1. Right-click your Arts.txt file\")\n",
    "        print(\"2. Select 'Copy'\")\n",
    "        print(\"3. Open the folder that just appeared\")\n",
    "        print(\"4. Right-click → Paste\")\n",
    "        os.startfile(safe_dir)\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        print(f\" Using file at: {input_path}\")\n",
    "        reviews = parse_arts_file(input_path)\n",
    "        helpfulness_data = calculate_helpfulness_score(reviews)\n",
    "        processed_data = calculate_reliability_scores(helpfulness_data)\n",
    "        df = generate_dataframe(processed_data)\n",
    "\n",
    "        # Save CSV to safe directory\n",
    "        output_path = os.path.join(safe_dir, \"average_scores12.csv\")\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"\\n CSV saved to: {output_path}\")\n",
    "\n",
    "        print(\"\\n Sample of dataframe:\")\n",
    "        print(df.head())\n",
    "\n",
    "        # Apply SVD\n",
    "        pivot_df, predicted_ratings, U, Vt = apply_svd(df, k=50)\n",
    "        R = pivot_df.values\n",
    "\n",
    "        # Print matrices (first 5x5)\n",
    "        print(\"\\n Original Rating Matrix (First 5x5):\")\n",
    "        print(pd.DataFrame(R[:5, :5], index=pivot_df.index[:5], columns=pivot_df.columns[:5]))\n",
    "\n",
    "        print(\"\\n Predicted Rating Matrix (First 5x5):\")\n",
    "        print(pd.DataFrame(predicted_ratings[:5, :5], index=pivot_df.index[:5], columns=pivot_df.columns[:5]))\n",
    "\n",
    "        # Loss calculation\n",
    "        loss = compute_loss(R, predicted_ratings, U, Vt)\n",
    "        print(f\"\\n Regularized Loss: {loss:.4f}\")\n",
    "\n",
    "        # Recommendations\n",
    "        user_index = 0\n",
    "        user_id = pivot_df.index[user_index]\n",
    "        top_preds = pd.Series(predicted_ratings[user_index], index=pivot_df.columns).sort_values(ascending=False).head(10)\n",
    "        print(f\"\\n Top 10 recommendations for user {user_id}:\\n{top_preds}\")\n",
    "\n",
    "        # Train-test evaluation\n",
    "        user_ids = pivot_df.index.tolist()\n",
    "        train_users, test_users = train_test_split(user_ids, test_size=0.2, random_state=42)\n",
    "        train_matrix = pivot_df.loc[train_users].values\n",
    "        test_matrix = pivot_df.loc[test_users].values\n",
    "\n",
    "        U_train, sigma_train, Vt_train = svds(train_matrix, k=50)\n",
    "        sigma_train = np.diag(sigma_train)\n",
    "        test_pred = np.dot(np.dot(U_train, sigma_train), Vt_train)[:len(test_users), :]\n",
    "\n",
    "        mask = test_matrix > 0\n",
    "        mse = mean_squared_error(test_matrix[mask], test_pred[mask])\n",
    "        hit_ratio = hit_ratio_at_k(test_matrix, test_pred, k=10)\n",
    "\n",
    "        print(f\"\\n MSE on test set: {mse:.4f}\")\n",
    "        print(f\" Hit Ratio@10: {hit_ratio:.4f}\")\n",
    "\n",
    "    except PermissionError as pe:\n",
    "        print(f\"\\n Critical Permission Error: {pe}\")\n",
    "        print(\"Run these commands in Admin Command Prompt:\")\n",
    "        print(f'  takeown /f \"{safe_dir}\" /r /d y')\n",
    "        print(f'  icacls \"{safe_dir}\" /grant \"%username%\":F /t')\n",
    "        print(\"Then restart your computer and try again\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n Unexpected Error: {e}\")\n",
    "        print(\"Common fixes:\")\n",
    "        print(\"1. Ensure Arts.txt has exactly 8 fields per review\")\n",
    "        print(\"2. Check file encoding is UTF-8\")\n",
    "        print(\"3. Reduce SVD k parameter if memory error occurs\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6716ecd4-b7b0-47c6-8bf4-fb8dcb45dd4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
